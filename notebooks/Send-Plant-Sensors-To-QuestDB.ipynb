{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c14dd7-9b46-4f67-bf44-5cd30a825070",
   "metadata": {},
   "source": [
    "# Send Factory Plant Sensors To QuestDB\n",
    "\n",
    "This notebook will produce simulated factory plant sensor data. The script simulates a \"realistic\" stream of sensor data with varying frequencies, data types, and behaviors, including downtime and value fluctuations. It provides flexibility to switch between real-time and historical data generation.\n",
    "\n",
    "### Data Generation Logic Summary\n",
    "\n",
    "The script simulates sensor data for ingestion into QuestDB, following these key steps:\n",
    "\n",
    "1. **Sensor Creation**:\n",
    "   - **Total Sensors**: A specified number of sensors (`TOTAL_SENSORS`) are generated using a custom device ID generation function.\n",
    "   - **Sensor IDs**: Each sensor is assigned a unique ID in the format of three letters followed by four hexadecimal digits (e.g., `AAA0001`).\n",
    "\n",
    "2. **Sensor Categorization**:\n",
    "   - **Frequency Categories**:\n",
    "     - **High-Frequency Sensors**: 20% of sensors.\n",
    "     - **Medium-Frequency Sensors**: 30% of sensors.\n",
    "     - **Low-Frequency Sensors**: 50% of sensors.\n",
    "   - **Data Types**:\n",
    "     - **Numeric Sensors**: 80% of sensors.\n",
    "     - **Text Sensors**: 20% of sensors.\n",
    "   - Sensors are randomly assigned to these categories to simulate a diverse set of devices.\n",
    "\n",
    "3. **Event Rate Calculation**:\n",
    "   - **Total Event Rate**: Defined by `RATE_PER_SECOND`.\n",
    "   - **Category Weights**:\n",
    "     - **High**: Weight of 1.\n",
    "     - **Medium**: Weight of 0.1.\n",
    "     - **Low**: Weight of 0.01.\n",
    "   - **Base Rate**: Calculated by dividing `RATE_PER_SECOND` by the sum of all category weights.\n",
    "   - **Per-Sensor Rate**:\n",
    "     - **High-Frequency Sensors**: `base_rate`.\n",
    "     - **Medium-Frequency Sensors**: `base_rate * 0.1`.\n",
    "     - **Low-Frequency Sensors**: `base_rate * 0.01`.\n",
    "   - This ensures that sensors in different categories send events at appropriate frequencies while respecting the total event rate.\n",
    "\n",
    "4. **Event Generation**:\n",
    "   - **Numeric Sensors**:\n",
    "     - Generate values that change slowly using small random fluctuations.\n",
    "     - Occasionally introduce larger jumps with a small probability (1% chance).\n",
    "   - **Text Sensors**:\n",
    "     - Randomly select messages from a predefined list of 100 messages (e.g., `\"message001\"` to `\"message100\"`).\n",
    "   - **System Name**:\n",
    "     - Each event includes a `system` symbol, randomly assigned from `\"system000\"` to `\"system019\"`.\n",
    "\n",
    "5. **Downtime Simulation**:\n",
    "   - **Downtime Probability**: Each sensor has a 1% chance of going down at each event.\n",
    "   - **Downtime Duration**: Sensors stay down for a specified duration (`DOWNTIME_DURATION`).\n",
    "   - **Status Handling**:\n",
    "     - Sensors can have statuses: `'active'`, `'stopping'`, or `'starting'`.\n",
    "     - When a sensor goes down, its status changes to `'stopping'` and stops generating events.\n",
    "     - After the downtime period, the sensor status changes to `'starting'` before resuming normal operation.\n",
    "\n",
    "6. **Timestamp Handling**:\n",
    "   - **Simulation Modes**:\n",
    "     - **Realtime Mode**:\n",
    "       - Events are timestamped with the current system time.\n",
    "       - The script sleeps as necessary to maintain the correct event rate.\n",
    "     - **Historical Mode**:\n",
    "       - Events are timestamped starting from a specified `START_DATETIME`.\n",
    "       - Simulated time advances based on event intervals without real-time delays.\n",
    "       - Optional delay (`DELAY_MS`) can be introduced to control ingestion speed.\n",
    "\n",
    "7. **Event Scheduling**:\n",
    "   - **Priority Queue**:\n",
    "     - Uses a min-heap (priority queue) to schedule events based on the next event time for each sensor.\n",
    "     - Efficiently processes sensors in order of their scheduled event times.\n",
    "   - **Event Loop**:\n",
    "     - Continues generating events until the total number of events (`TOTAL_NUMBER_OF_EVENTS`) is reached.\n",
    "     - In historical mode, events are generated as fast as possible without waiting.\n",
    "\n",
    "8. **Data Ingestion**:\n",
    "   - **QuestDB Client**:\n",
    "     - Uses the QuestDB Python client to send data directly to QuestDB.\n",
    "     - The `sender.row()` method is used to ingest each event, specifying symbols, columns, and timestamp.\n",
    "     - Relies on the client's automatic flushing mechanism for efficiency.\n",
    "\n",
    "9. **Parallel Processing**:\n",
    "   - **Multiprocessing Pool**:\n",
    "     - The script uses a multiprocessing pool to run multiple sender processes in parallel.\n",
    "     - Sensors are evenly distributed among the processes.\n",
    "     - Each process handles its share of sensors and events independently.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a45d375a-019c-484f-849c-8ddcecb86406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore deprecation warnings in this demo\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4bff5a-bdf5-4e44-8fc7-60a930461cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg as pg\n",
    "import os\n",
    "\n",
    "# Fetch environment variables with defaults\n",
    "host = os.getenv('QDB_CLIENT_HOST', 'questdb')\n",
    "port = os.getenv('QDB_CLIENT_PORT', '8812')\n",
    "user = os.getenv('QDB_CLIENT_USER', 'admin')\n",
    "password = os.getenv('QDB_CLIENT_PASSWORD', 'quest')\n",
    "\n",
    "# Create the connection string using the environment variables or defaults\n",
    "conn_str = f'user={user} password={password} host={host} port={port} dbname=qdb'\n",
    "\n",
    "with pg.connect(conn_str, autocommit=True) as connection:\n",
    "    with connection.cursor() as cur:\n",
    "        cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS 'plant_sensors' (\n",
    "          timestamp TIMESTAMP,\n",
    "          system SYMBOL CACHE,\n",
    "          address SYMBOL CAPACITY 100000 CACHE,\n",
    "          value DOUBLE,\n",
    "          text VARCHAR,\n",
    "          status SYMBOL  NOCACHE\n",
    "        ) timestamp (timestamp) PARTITION BY DAY WAL \n",
    "          DEDUP UPSERT KEYS(timestamp, system, address);\n",
    "\"\"\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655581a-d0b8-4157-b0c8-6b3d5bc996ca",
   "metadata": {},
   "source": [
    "## Sending the data to QuestDB\n",
    "\n",
    "This script will keep sending data until you click stop or exit the notebook, or until the `TOTAL_NUMBER_OF_EVENTS` number is reached. \n",
    "\n",
    "While the script is running, you can check the data in the table directly at QuestDB's web console at http://localhost:9000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95a61bca-88ab-4ed0-a18b-d813fd156e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion started. Connecting to 172.31.42.41:9000\n",
      "Sender 0 will send data for 1800 sensors\n",
      "Sender 1 will send data for 1800 sensors\n",
      "Sender 3 will send data for 1800 sensors\n",
      "Sender 2 will send data for 1800 sensors\n",
      "Sender 5 will send data for 1800 sensors\n",
      "Sender 6 will send data for 1800 sensors\n",
      "Sender 4 will send data for 1800 sensors\n",
      "Sender 7 will send data for 1800 sensors\n",
      "Sender 8 will send data for 1800 sensors\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "Sender 9 will send data for 1800 sensors\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n",
      "https::addr=172.31.42.41:9000;tls_verify=unsafe_off;token=qt1H8Mi_vPUpt_R7ByDdJ7_kRIiieNb_BFKdjBDqxp6wh8;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-15:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-20:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 261\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    260\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIngestion started. Connecting to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHTTP_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mparallel_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTOTAL_NUMBER_OF_EVENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_SENDERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHTTP_ENDPOINT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mREST_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 251\u001b[0m, in \u001b[0;36mparallel_send\u001b[0;34m(total_events, num_senders, http_endpoint, auth)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mnum_senders) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m    250\u001b[0m     sender_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(num_senders)\n\u001b[0;32m--> 251\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43msend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msensor_ids_chunks\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender_events\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_endpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msender_ids\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from questdb.ingress import Sender, IngressError, TimestampNanos\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime, timedelta\n",
    "import heapq  # For efficient scheduling\n",
    "\n",
    "# Device ID generation\n",
    "def generate_device_id(index):\n",
    "    letters = index // (16**4) % (26**3)\n",
    "    letter_part = ''.join(chr(65 + (letters // (26**i) % 26)) for i in range(3)[::-1])\n",
    "    hex_part = format(index % (16**4), '04x').upper()\n",
    "    return f\"{letter_part}{hex_part}\"\n",
    "\n",
    "# Constants\n",
    "HTTP_ENDPOINT = os.getenv('QUESTDB_HTTP_ENDPOINT', 'localhost:9009')\n",
    "REST_TOKEN = os.getenv('QUESTDB_REST_TOKEN')\n",
    "\n",
    "TOTAL_SENSORS = 18000  # Adjust as needed\n",
    "RATE_PER_SECOND = 2000  # Total average number of events to generate per second\n",
    "TOTAL_NUMBER_OF_EVENTS = 1000000 #56_050_000  # Total number of events to send across all processes\n",
    "\n",
    "# Sensor frequency distribution\n",
    "HIGH_FREQ_PERCENT = 0.2  # 20% high-frequency sensors\n",
    "MEDIUM_FREQ_PERCENT = 0.3  # 30% medium-frequency sensors\n",
    "LOW_FREQ_PERCENT = 0.5  # 50% low-frequency sensors\n",
    "\n",
    "# Sensor data type distribution\n",
    "NUMERIC_PERCENT = 0.8  # 80% numeric sensors\n",
    "TEXT_PERCENT = 0.2     # 20% text sensors\n",
    "\n",
    "# Downtime simulation constants\n",
    "DOWNTIME_PROBABILITY = 0.01  # Probability of a sensor going down at each event\n",
    "DOWNTIME_DURATION = 60  # Downtime duration in seconds\n",
    "\n",
    "# Simulation mode: 'realtime' or 'historical'\n",
    "SIMULATION_MODE = 'realtime'  # Set to 'historical' for historical simulation\n",
    "START_DATETIME = datetime(2024, 9, 1, 0, 0, 0)  # Start datetime for historical simulation\n",
    "DELAY_MS = 0  # Delay in milliseconds when generating data as fast as possible\n",
    "\n",
    "NUM_SENDERS = 10  # Adjust as needed\n",
    "\n",
    "# Generate sensor IDs\n",
    "sensor_ids = [generate_device_id(i) for i in range(TOTAL_SENSORS)]\n",
    "\n",
    "# Assign sensors to frequency categories\n",
    "random.shuffle(sensor_ids)  # Shuffle sensor IDs to randomize assignments\n",
    "\n",
    "NUM_HIGH_FREQ_SENSORS = int(TOTAL_SENSORS * HIGH_FREQ_PERCENT)\n",
    "NUM_MEDIUM_FREQ_SENSORS = int(TOTAL_SENSORS * MEDIUM_FREQ_PERCENT)\n",
    "NUM_LOW_FREQ_SENSORS = TOTAL_SENSORS - NUM_HIGH_FREQ_SENSORS - NUM_MEDIUM_FREQ_SENSORS\n",
    "\n",
    "high_freq_sensors = sensor_ids[:NUM_HIGH_FREQ_SENSORS]\n",
    "medium_freq_sensors = sensor_ids[NUM_HIGH_FREQ_SENSORS:NUM_HIGH_FREQ_SENSORS + NUM_MEDIUM_FREQ_SENSORS]\n",
    "low_freq_sensors = sensor_ids[NUM_HIGH_FREQ_SENSORS + NUM_MEDIUM_FREQ_SENSORS:]\n",
    "\n",
    "# Assign data types to sensors\n",
    "random.shuffle(sensor_ids)  # Shuffle again before assigning data types\n",
    "NUM_NUMERIC_SENSORS = int(TOTAL_SENSORS * NUMERIC_PERCENT)\n",
    "NUM_TEXT_SENSORS = TOTAL_SENSORS - NUM_NUMERIC_SENSORS\n",
    "\n",
    "numeric_sensors = set(sensor_ids[:NUM_NUMERIC_SENSORS])\n",
    "text_sensors = set(sensor_ids[NUM_NUMERIC_SENSORS:])\n",
    "\n",
    "# Build sensor info dictionary\n",
    "sensor_info = {}\n",
    "for sensor_id in sensor_ids:\n",
    "    if sensor_id in high_freq_sensors:\n",
    "        category = 'high'\n",
    "    elif sensor_id in medium_freq_sensors:\n",
    "        category = 'medium'\n",
    "    else:\n",
    "        category = 'low'\n",
    "    if sensor_id in numeric_sensors:\n",
    "        data_type = 'numeric'\n",
    "        last_value = random.uniform(0, 100)\n",
    "    else:\n",
    "        data_type = 'text'\n",
    "        last_value = None\n",
    "    sensor_info[sensor_id] = {\n",
    "        'category': category,\n",
    "        'data_type': data_type,\n",
    "        'status': 'active',\n",
    "        'next_event_time': 0.0,  # Initialize to 0 for historical mode\n",
    "        'last_value': last_value,\n",
    "    }\n",
    "\n",
    "# Calculate per-sensor event rates to match RATE_PER_SECOND\n",
    "# Define weights for each category\n",
    "total_weight = (NUM_HIGH_FREQ_SENSORS * 1 +\n",
    "                NUM_MEDIUM_FREQ_SENSORS * 0.1 +\n",
    "                NUM_LOW_FREQ_SENSORS * 0.01) or 1e-6  # Prevent division by zero\n",
    "\n",
    "base_rate = RATE_PER_SECOND / total_weight\n",
    "\n",
    "# Assign rates to sensors\n",
    "for sensor_id, info in sensor_info.items():\n",
    "    if info['category'] == 'high':\n",
    "        info['rate'] = base_rate\n",
    "    elif info['category'] == 'medium':\n",
    "        info['rate'] = base_rate * 0.1\n",
    "    else:  # 'low'\n",
    "        info['rate'] = base_rate * 0.01\n",
    "    # Ensure rate is not zero\n",
    "    if info['rate'] <= 0:\n",
    "        info['rate'] = 1e-6  # Small non-zero rate\n",
    "\n",
    "# List of possible text messages\n",
    "TEXT_MESSAGES = [f\"message{str(i).zfill(3)}\" for i in range(1, 101)]\n",
    "\n",
    "def send(sender_id, sensor_ids_chunk, total_events, http_endpoint: str = None, auth=None):\n",
    "    sys.stdout.write(f\"Sender {sender_id} will send data for {len(sensor_ids_chunk)} sensors\\n\")\n",
    "    events_sent = 0  # Total events sent by this sender\n",
    "\n",
    "    try:\n",
    "        if auth:\n",
    "            conf = f'https::addr={http_endpoint};tls_verify=unsafe_off;token={auth};'\n",
    "        else:\n",
    "            conf = f'http::addr={http_endpoint};'\n",
    "\n",
    "        sys.stdout.write(conf + '\\n')\n",
    "        with Sender.from_conf(conf) as sender:\n",
    "            # Initialize a priority queue (min-heap) based on next_event_time\n",
    "            sensor_heap = []\n",
    "            for sensor_id in sensor_ids_chunk:\n",
    "                info = sensor_info[sensor_id]\n",
    "                # Initialize next_event_time to 0 for historical mode\n",
    "                if SIMULATION_MODE == 'historical':\n",
    "                    info['next_event_time'] = 0.0\n",
    "                else:\n",
    "                    info['next_event_time'] = time.time()\n",
    "                heapq.heappush(sensor_heap, (info['next_event_time'], sensor_id))\n",
    "\n",
    "            while events_sent < total_events and sensor_heap:\n",
    "                next_event_time, sensor_id = heapq.heappop(sensor_heap)\n",
    "                info = sensor_info[sensor_id]\n",
    "\n",
    "                # In historical mode, no need to sleep; process events as fast as possible\n",
    "                if SIMULATION_MODE != 'historical':\n",
    "                    current_time = time.time()\n",
    "                    sleep_time = next_event_time - current_time\n",
    "                    if sleep_time > 0:\n",
    "                        time.sleep(sleep_time)\n",
    "                        current_time = time.time()\n",
    "                else:\n",
    "                    current_time = next_event_time  # Use simulated time\n",
    "\n",
    "                # Check if sensor is active\n",
    "                if info['status'] == 'active' or info['status'] == 'starting':\n",
    "                    # Generate data\n",
    "                    system_name = f\"system{str(random.randint(0, 19)).zfill(3)}\"\n",
    "                    value = None\n",
    "                    text = None\n",
    "\n",
    "                    if info['data_type'] == 'text':\n",
    "                        # Text sensor\n",
    "                        text = random.choice(TEXT_MESSAGES)\n",
    "                    else:\n",
    "                        # Numeric sensor\n",
    "                        last_value = info['last_value']\n",
    "                        # Small change\n",
    "                        value = last_value + random.uniform(-1, 1)\n",
    "                        # Occasional larger jump\n",
    "                        if random.random() < 0.01:\n",
    "                            value += random.uniform(-10, 10)\n",
    "                        info['last_value'] = value\n",
    "\n",
    "                    # Simulate downtime\n",
    "                    if random.random() < DOWNTIME_PROBABILITY:\n",
    "                        info['status'] = 'stopping'\n",
    "                        info['downtime_remaining'] = DOWNTIME_DURATION\n",
    "                    else:\n",
    "                        info['status'] = 'active'\n",
    "\n",
    "                    # Determine timestamp\n",
    "                    if SIMULATION_MODE == 'historical':\n",
    "                        timestamp = START_DATETIME + timedelta(seconds=next_event_time)\n",
    "                        timestamp_nanos = TimestampNanos(int(timestamp.timestamp() * 1e9))\n",
    "                    else:\n",
    "                        timestamp_nanos = TimestampNanos(int(current_time * 1e9))\n",
    "\n",
    "                    # Send data to QuestDB\n",
    "                    sender.row(\n",
    "                        'plant_sensors',\n",
    "                        symbols={\n",
    "                            'system': system_name,\n",
    "                            'address': sensor_id,\n",
    "                            'status': info['status']\n",
    "                        },\n",
    "                        columns={\n",
    "                            'value': value,\n",
    "                            'text': text\n",
    "                        },\n",
    "                        at=timestamp_nanos\n",
    "                    )\n",
    "\n",
    "                    events_sent += 1\n",
    "\n",
    "                    # Update next event time\n",
    "                    interval = 1 / info['rate']\n",
    "                    info['next_event_time'] = next_event_time + interval\n",
    "\n",
    "                    # Add sensor back to the heap with updated next_event_time\n",
    "                    heapq.heappush(sensor_heap, (info['next_event_time'], sensor_id))\n",
    "\n",
    "                elif info['status'] == 'stopping':\n",
    "                    # Decrease downtime remaining\n",
    "                    if SIMULATION_MODE == 'historical':\n",
    "                        # In historical mode, advance downtime_remaining based on event intervals\n",
    "                        downtime_elapsed = 1 / info['rate']\n",
    "                    else:\n",
    "                        downtime_elapsed = current_time - info.get('last_update_time', current_time)\n",
    "                    info['downtime_remaining'] -= downtime_elapsed\n",
    "                    if info['downtime_remaining'] <= 0:\n",
    "                        info['status'] = 'starting'\n",
    "                        info['next_event_time'] = next_event_time  # Resume immediately\n",
    "                        del info['downtime_remaining']\n",
    "                        # Add sensor back to the heap\n",
    "                        heapq.heappush(sensor_heap, (info['next_event_time'], sensor_id))\n",
    "                    else:\n",
    "                        info['last_update_time'] = current_time\n",
    "                        # Re-add sensor to the heap with updated downtime\n",
    "                        info['next_event_time'] = next_event_time + (1 / info['rate'])\n",
    "                        heapq.heappush(sensor_heap, (info['next_event_time'], sensor_id))\n",
    "\n",
    "                if DELAY_MS > 0 and SIMULATION_MODE == 'historical':\n",
    "                    time.sleep(DELAY_MS / 1000.0)  # Optional delay to control ingestion speed\n",
    "\n",
    "            sys.stdout.write(f\"Sender {sender_id} finished sending {events_sent} events\\n\")\n",
    "\n",
    "    except IngressError as e:\n",
    "        sys.stderr.write(f'Sender {sender_id} encountered an error: {e}\\n')\n",
    "\n",
    "def parallel_send(total_events, num_senders: int, http_endpoint, auth):\n",
    "    events_per_sender = total_events // num_senders\n",
    "    remaining_events = total_events % num_senders\n",
    "\n",
    "    sender_events = [events_per_sender] * num_senders\n",
    "    for i in range(remaining_events):  # Distribute remaining events\n",
    "        sender_events[i] += 1\n",
    "\n",
    "    # Distribute sensors among senders\n",
    "    sensor_ids_chunks = [[] for _ in range(num_senders)]\n",
    "    for idx, sensor_id in enumerate(sensor_info.keys()):\n",
    "        sensor_ids_chunks[idx % num_senders].append(sensor_id)\n",
    "\n",
    "    with Pool(processes=num_senders) as pool:\n",
    "        sender_ids = range(num_senders)\n",
    "        pool.starmap(\n",
    "            send,\n",
    "            [\n",
    "                (sender_id, sensor_ids_chunks[sender_id], sender_events[sender_id], http_endpoint, auth)\n",
    "                for sender_id in sender_ids\n",
    "            ]\n",
    "        )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.stdout.write(f'Ingestion started. Connecting to {HTTP_ENDPOINT}\\n')\n",
    "    parallel_send(TOTAL_NUMBER_OF_EVENTS, NUM_SENDERS, HTTP_ENDPOINT, REST_TOKEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca1e94b-b116-45a3-87c1-cc8b0ca21804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
