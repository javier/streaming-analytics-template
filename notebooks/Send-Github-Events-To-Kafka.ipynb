{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cab2d5a-aaf8-44ea-ab41-22d24a413943",
   "metadata": {},
   "source": [
    "**Note:** This script needs a github token to be executed. If you set and environment variable named `GITHUB_TOKEN` before running docker-compose up, or if you manually passed this variable to your container, the script will use it. Otherwise you need to enter the variable value at line 10, replacing the literal `<YOUR_GITHUB_TOKEN>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e464b-bd96-403e-9a1e-601ce3c3b4e9",
   "metadata": {},
   "source": [
    "# Sending GitHub Events To Kafka\n",
    "\n",
    "Sending events to Kafka means connecting to a Kafka broker and pushing data to one or more topics. \n",
    "In this case the broker lives within the same docker-componse environment, so we access via the container name: `broker:29002`. \n",
    "For the topic name we will be using `github_events` as we have other components that will be consuming events from those topics. We have configured those consumers to read JSON, so we are sending the data to Kafka already in JSON format to simplify this example.\n",
    "\n",
    "Data is retrieved from the GitHub public events API, and will request new data every 10 seconds to avoid any api rate limits.\n",
    "\n",
    "If you prefer to ingest data from outside a Jupyter Notebook, you have scripts in Python, Go, Rust, JAVA, and NodeJS available in [this same repository](https://github.com/javier/time-series-streaming-analytics-template?tab=readme-ov-file#ingestion). \n",
    "\n",
    "It would also be possible to ingest data directly into QuestDB, skipping Kafka altogether. That would simplify the deployment and would decrease latency (although for most use cases this would not be noticeable). On the other hand, having a message broker in frong of your database gives you more flexibility in your data analytics pipeline. There is a [Jupyter Notebook](./IoTEventsToQuestDB.ipynb) in this repository to ingest data directly into QuestDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca60068-7455-4aea-9880-52ebf739c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent event: PushEvent from kloggenberg/kloggenberg\n",
      "Sent event: CreateEvent from hugobaudchon/geodataset\n",
      "Sent event: CreateEvent from hemunaidu/hemunaidu\n",
      "Sent event: PushEvent from adzst/Github-adzst\n",
      "Sent event: PushEvent from husnapupita/WedusKripto4\n",
      "Sent event: PushEvent from leesadie/ubcballet\n",
      "Sent event: WatchEvent from ltp19940206/Adobe-Animate\n",
      "Sent event: PushEvent from FelipeBaglioliUFPR/pollution_parana\n",
      "Sent event: PushEvent from likhonsible/Flash-USDT-Sender\n",
      "Sent event: PushEvent from WarnerMedia/artemis\n",
      "Sent event: PullRequestEvent from github/dmca\n",
      "Sent event: PushEvent from chromium/pdfium\n",
      "Sent event: CreateEvent from augustofarina/GitHubActions\n",
      "Sent event: CreateEvent from av3714/Mapbox-Web-App-Google-Maps-Clone\n",
      "Sent event: PushEvent from tb2-sy/tb2-sy.github.io\n",
      "Sent event: PushEvent from static-web-apps-testing-org/swa4a7611cebf1840a39f493b35203e5306\n",
      "Sent event: PushEvent from caesarmaulana01/ChatBot-Project\n",
      "Sent event: PushEvent from onerandomusername/monty-python\n",
      "Sent event: PushEvent from stangri/luci\n",
      "Sent event: ForkEvent from learn-co-curriculum/phase-0-pac-3-intro-to-functions\n",
      "Sent event: IssueCommentEvent from rppicomidi/usb_midi_host\n",
      "Sent event: PushEvent from DhiraPT/leetcode\n",
      "Sent event: PullRequestEvent from codecov/gazebo\n",
      "Sent event: PushEvent from webyanfeng/my_auto_code_demo\n",
      "Sent event: PushEvent from hungtugialong/lavapoint\n",
      "Sent event: PushEvent from silasmas/admindikitivi\n",
      "Sent event: PullRequestEvent from ZainCheung/shadcnui-boilerplate\n",
      "Sent event: CreateEvent from Vipulcoder666/DSA-in-Python\n",
      "Sent event: PushEvent from richardsondev/rmp-outages\n",
      "Sent event: PushEvent from MatthewDelego/MatthewDelego.github.io\n",
      "Sleeping for 10 seconds....\n"
     ]
    }
   ],
   "source": [
    "from github import Github, GithubException\n",
    "import requests\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', '<YOUR_GITHUB_TOKEN>')  # Fetch GitHub token from environment variable\n",
    "if not GITHUB_TOKEN:\n",
    "    raise ValueError(\"GitHub token not found in environment variables.\")\n",
    "\n",
    "KAFKA_TOPIC = 'github_events'       # Kafka topic to produce messages to\n",
    "KAFKA_BROKER = 'broker:29092'     # Kafka broker address\n",
    "FETCH_INTERVAL = 10                 # Time interval between fetches in seconds\n",
    "GITHUB_EVENTS_URL = 'https://api.github.com/events'\n",
    "\n",
    "# Initialize GitHub client\n",
    "g = Github(GITHUB_TOKEN, per_page=100)\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers=[KAFKA_BROKER],\n",
    "                         value_serializer=lambda m: json.dumps(m).encode('ascii'))\n",
    "\n",
    "# Function to fetch and send public events\n",
    "def fetch_and_send_events(etag=None):\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "    }\n",
    "    if etag:\n",
    "        headers['If-None-Match'] = etag\n",
    "\n",
    "    response = requests.get(GITHUB_EVENTS_URL, headers=headers)\n",
    "\n",
    "    if response.status_code == 304:  # Not Modified\n",
    "        print(\"No new events since last check.\")\n",
    "        return etag\n",
    "    elif response.status_code != 200:\n",
    "        raise GithubException(response.status_code, response.json())\n",
    "\n",
    "    new_etag = response.headers.get('ETag')\n",
    "    events = response.json()\n",
    "\n",
    "    for event in events:\n",
    "        # Uncomment the following lines if you want to send the event timestamp \n",
    "        # rather than allow QuestDB to use the server timestamp\n",
    "        # created_at_datetime = datetime.strptime(event.get('created_at'), '%Y-%m-%dT%H:%M:%SZ')\n",
    "        # created_at_microseconds = int(time.mktime(created_at_datetime.timetuple()) * 1e6)\n",
    "\n",
    "        event_data = {\n",
    "            'type': event.get('type'),\n",
    "            'repo': event.get('repo', {}).get('name', 'None'),\n",
    "            'actor': event.get('actor', {}).get('login', 'Unknown'),\n",
    "            # Uncomment the following line if using created_at_microseconds\n",
    "            # 'created_at': created_at_microseconds\n",
    "        }\n",
    "        producer.send(KAFKA_TOPIC, event_data)\n",
    "        print(f\"Sent event: {event.get('type')} from {event.get('repo', {}).get('name', 'None')}\")\n",
    "\n",
    "    return new_etag\n",
    "\n",
    "# Main loop\n",
    "etag = None\n",
    "try:\n",
    "    while True:\n",
    "        rate_limit = g.get_rate_limit().core\n",
    "        if rate_limit.remaining == 0:\n",
    "            reset_time = rate_limit.reset.timestamp()\n",
    "            sleep_time = max(reset_time - time.time(), 1)\n",
    "            print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "        else:\n",
    "            etag = fetch_and_send_events(etag)\n",
    "            print(f\"Sleeping for {FETCH_INTERVAL} seconds....\")\n",
    "            time.sleep(FETCH_INTERVAL)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75225e7-8923-4bb5-af37-47f749195035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
