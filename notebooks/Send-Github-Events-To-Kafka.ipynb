{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cab2d5a-aaf8-44ea-ab41-22d24a413943",
   "metadata": {},
   "source": [
    "**Note:** This script needs a github token to be executed. If you set and environment variable named `GITHUB_TOKEN` before running docker-compose up, or if you manually passed this variable to your container, the script will use it. Otherwise you need to enter the variable value at line 10, replacing the literal `<YOUR_GITHUB_TOKEN>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9e464b-bd96-403e-9a1e-601ce3c3b4e9",
   "metadata": {},
   "source": [
    "# Sending GitHub Events To Kafka\n",
    "\n",
    "Sending events to Kafka means connecting to a Kafka broker and pushing data to one or more topics. \n",
    "In this case the broker lives within the same docker-componse environment, so we access via the container name: `broker:29002`. \n",
    "For the topic name we will be using `github_events` as we have other components that will be consuming events from those topics. We have configured those consumers to read JSON, so we are sending the data to Kafka already in JSON format to simplify this example.\n",
    "\n",
    "Data is retrieved from the GitHub public events API, and will request new data every 10 seconds to avoid any api rate limits.\n",
    "\n",
    "If you prefer to ingest data from outside a Jupyter Notebook, you have scripts in Python, Go, Rust, JAVA, and NodeJS available in [this same repository](https://github.com/javier/time-series-streaming-analytics-template?tab=readme-ov-file#ingestion). \n",
    "\n",
    "It would also be possible to ingest data directly into QuestDB, skipping Kafka altogether. That would simplify the deployment and would decrease latency (although for most use cases this would not be noticeable). On the other hand, having a message broker in frong of your database gives you more flexibility in your data analytics pipeline. There is a [Jupyter Notebook](./IoTEventsToQuestDB.ipynb) in this repository to ingest data directly into QuestDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca60068-7455-4aea-9880-52ebf739c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent event: PushEvent from spinalcom/spinal-env-viewer-plugin-graph-manager\n",
      "Sent event: IssueCommentEvent from status-im/status-go\n",
      "Sent event: PullRequestEvent from aws-aemilia-pdx/Github-PR-Commit-Integration-Test-DoNotTouch-GitHubAutoBuildPrPreviewCanaryTest-v1-prod-us-west-2\n",
      "Sent event: ReleaseEvent from budka-tech/snip-common-go\n",
      "Sent event: IssuesEvent from liberu-crm/crm-laravel\n",
      "Sent event: PushEvent from brand22/d3\n",
      "Sent event: PushEvent from go-cinch/argocd-app\n",
      "Sent event: PushEvent from cguilloteau/cguilloteau.github.io\n",
      "Sent event: PushEvent from Ayatisonkar/DSA\n",
      "Sent event: WatchEvent from exo-explore/exo\n",
      "Sent event: PushEvent from athombv/node-homey\n",
      "Sent event: PushEvent from drymonsterblack462wj56/1an-Overwatch2n\n",
      "Sent event: PushEvent from timherreijgers/LoggingVisualizer\n",
      "Sent event: PushEvent from BurmeseTV/ios\n",
      "Sent event: IssueCommentEvent from ITISFoundation/osparc-simcore\n",
      "Sent event: WatchEvent from williamleif/GraphSAGE\n",
      "Sent event: PullRequestEvent from homewizard/api-documentation\n",
      "Sent event: ForkEvent from google/timesketch\n",
      "Sent event: PushEvent from BurmeseTV/modifysoco\n",
      "Sent event: IssuesEvent from dart-lang/sdk\n",
      "Sent event: CreateEvent from MetadataGitTesting/MggZmdih\n",
      "Sent event: PullRequestEvent from HelenDrug/Persons_React_App\n",
      "Sent event: PushEvent from topoteretes/cognee\n",
      "Sent event: DeleteEvent from brewcoua/Invaders-SDP\n",
      "Sent event: WatchEvent from westnordost/osmapi\n",
      "Sent event: PushEvent from PetersonCD/PetersonCD\n",
      "Sent event: PushEvent from immxmmi/ml2\n",
      "Sent event: PushEvent from haythemgalelem/save_quote\n",
      "Sent event: PushEvent from RepoScanning/Scanning\n",
      "Sent event: PushEvent from ForgeFlow/sale-promotion\n",
      "Sleeping for 10 seconds....\n",
      "Sent event: PullRequestReviewEvent from loculus-project/loculus\n",
      "Sent event: PushEvent from savushkin-r-d/ptusa_main\n",
      "Sent event: PushEvent from Kishore-r-77/java\n",
      "Sent event: PushEvent from CodeRedModding/CodeRed-Retrievers\n",
      "Sent event: IssuesEvent from olvidalo/obsidian-chord-sheets\n",
      "Sent event: PushEvent from heytrgithub/degisiklik-yapan-sistem\n",
      "Sent event: WatchEvent from oblador/react-native-keychain\n",
      "Sent event: CreateEvent from ShahadAlnaamani/AreaCalculator\n",
      "Sent event: PushEvent from kauazinobrabo45/AlunosUnidosJamaisSeraoVencidos\n",
      "Sent event: PushEvent from radzenhq/radzen-blazor\n",
      "Sent event: PushEvent from aaronfranke/godot\n",
      "Sent event: ForkEvent from JRimIT/web-NikeShoes\n",
      "Sent event: PushEvent from Marco7507/sdv-archi-quality-test\n",
      "Sent event: PushEvent from jaroschek/homematic-node-exporter\n",
      "Sent event: PushEvent from Bopster410/highload-homework\n",
      "Sent event: CreateEvent from Phil-Chuong/Travel-Share\n",
      "Sent event: PushEvent from MetadataGitTesting/N1o7ET56\n",
      "Sent event: CreateEvent from MetadataGitTesting/6AfQa5ya\n",
      "Sent event: CreateEvent from Phil-Chuong/Travel-Share\n",
      "Sent event: PushEvent from eth-protocol-fellows/cohort-five\n",
      "Sent event: CreateEvent from ark9198/DAA-Assignment-\n",
      "Sent event: IssueCommentEvent from ParkJong-Hun/wihd\n",
      "Sent event: WatchEvent from natanrolnik/monday-night-16-05-22\n",
      "Sent event: CreateEvent from xplorer-io/xplorers-api\n",
      "Sent event: MemberEvent from hilmiramadani/ALPRO_Hilmi_Ramadani_103112430016\n",
      "Sent event: PullRequestEvent from google-test/signclav2-probe-repo\n",
      "Sent event: CreateEvent from Anar0505/miranatest\n",
      "Sent event: WatchEvent from Rabbitminers/Extended-Bogeys\n",
      "Sent event: IssueCommentEvent from FreeCAD/FreeCAD\n",
      "Sent event: PushEvent from Prayag-09/XORA--Landing-Page\n",
      "Sleeping for 10 seconds....\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "from github import Github, GithubException\n",
    "import requests\n",
    "from kafka import KafkaProducer\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "GITHUB_TOKEN = os.getenv('GITHUB_TOKEN', '<YOUR_GITHUB_TOKEN>')  # Fetch GitHub token from environment variable\n",
    "if not GITHUB_TOKEN:\n",
    "    raise ValueError(\"GitHub token not found in environment variables.\")\n",
    "\n",
    "KAFKA_TOPIC = 'github_events'       # Kafka topic to produce messages to\n",
    "KAFKA_BROKERS = ['broker:29092','broker-2:29092']\n",
    "FETCH_INTERVAL = 10                 # Time interval between fetches in seconds\n",
    "GITHUB_EVENTS_URL = 'https://api.github.com/events'\n",
    "\n",
    "\n",
    "# Initialize GitHub client\n",
    "g = Github(GITHUB_TOKEN, per_page=100)\n",
    "\n",
    "# Initialize Kafka producer\n",
    "producer = KafkaProducer(bootstrap_servers=KAFKA_BROKERS,\n",
    "                         value_serializer=lambda m: json.dumps(m).encode('ascii'))\n",
    "\n",
    "# Function to fetch and send public events\n",
    "def fetch_and_send_events(etag=None):\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_TOKEN}',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "    }\n",
    "    if etag:\n",
    "        headers['If-None-Match'] = etag\n",
    "\n",
    "    response = requests.get(GITHUB_EVENTS_URL, headers=headers)\n",
    "\n",
    "    if response.status_code == 304:  # Not Modified\n",
    "        print(\"No new events since last check.\")\n",
    "        return etag\n",
    "    elif response.status_code != 200:\n",
    "        raise GithubException(response.status_code, response.json())\n",
    "\n",
    "    new_etag = response.headers.get('ETag')\n",
    "    events = response.json()\n",
    "\n",
    "    for event in events:\n",
    "        # Uncomment the following lines if you want to send the event timestamp \n",
    "        # rather than allow QuestDB to use the server timestamp\n",
    "        # created_at_datetime = datetime.strptime(event.get('created_at'), '%Y-%m-%dT%H:%M:%SZ')\n",
    "        # created_at_microseconds = int(time.mktime(created_at_datetime.timetuple()) * 1e6)\n",
    "\n",
    "        event_data = {\n",
    "            'type': event.get('type'),\n",
    "            'repo': event.get('repo', {}).get('name', 'None'),\n",
    "            'actor': event.get('actor', {}).get('login', 'Unknown'),\n",
    "            # Uncomment the following line if using created_at_microseconds\n",
    "            # 'created_at': created_at_microseconds\n",
    "        }\n",
    "        producer.send(KAFKA_TOPIC, event_data)\n",
    "        print(f\"Sent event: {event.get('type')} from {event.get('repo', {}).get('name', 'None')}\")\n",
    "\n",
    "    return new_etag\n",
    "\n",
    "# Main loop\n",
    "etag = None\n",
    "try:\n",
    "    while True:\n",
    "        rate_limit = g.get_rate_limit().core\n",
    "        if rate_limit.remaining == 0:\n",
    "            reset_time = rate_limit.reset.timestamp()\n",
    "            sleep_time = max(reset_time - time.time(), 1)\n",
    "            print(f\"Rate limit exceeded. Sleeping for {sleep_time} seconds.\")\n",
    "            time.sleep(sleep_time)\n",
    "        else:\n",
    "            etag = fetch_and_send_events(etag)\n",
    "            print(f\"Sleeping for {FETCH_INTERVAL} seconds....\")\n",
    "            time.sleep(FETCH_INTERVAL)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopping...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75225e7-8923-4bb5-af37-47f749195035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
