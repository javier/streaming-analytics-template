{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0868bc-01bb-4296-8206-bad1c9b9da83",
   "metadata": {},
   "source": [
    "# Send Trades To Kafka\n",
    "\n",
    "This notebook will read the `./tradesMarch.csv` file to read trading events, and will send the events to Apache Kafka. Data will be then processed by Kafka Connect and will eventually end up on a QuestDB table.\n",
    "\n",
    "We first create the QuestDB table. It would automatically be created if it didn't exist in any case, but this way we can see the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf9613c-bf7d-47be-8235-dab0de85e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore deprecation warnings in this demo\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9835b8-2b20-4b1c-b893-5ef647db99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg as pg\n",
    "\n",
    "\n",
    "conn_str = 'user=admin password=quest host=questdb port=8812 dbname=qdb'\n",
    "with pg.connect(conn_str, autocommit=True) as connection:\n",
    "    with connection.cursor() as cur:\n",
    "        cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS  'trades' (\n",
    "  symbol SYMBOL capacity 256 CACHE,\n",
    "  side SYMBOL capacity 256 CACHE,\n",
    "  price DOUBLE,\n",
    "  amount DOUBLE,\n",
    "  timestamp TIMESTAMP\n",
    ") timestamp (timestamp) PARTITION BY DAY WAL DEDUP UPSERT KEYS(timestamp, symbol, side);\n",
    "\"\"\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e215-ffd0-4aef-b526-a65143e7e554",
   "metadata": {},
   "source": [
    "## Sending the data to Kafka\n",
    "\n",
    "Now we read the `./tradesMarch.csv` file and we convert every row to Avro binary format before we send to Kafka into a topic named `trades`.\n",
    "\n",
    "By default, the script will override the original date with the current date and\n",
    " will wait 50ms between events before sending to Kafka, to simulate a real time stream and provide\n",
    "a nicer visualization. You can override those configurations by changing the constants in the script. \n",
    "\n",
    "This script will keep sending data until you click stop or exit the notebook, or until the end of the file is reached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea7e3177-5269-433a-82af-5618181e90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n",
      "Message delivered to trades [0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m     avro_producer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 67\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m value \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mside\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mside\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m: timestamp_micros\n\u001b[1;32m     64\u001b[0m }\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DELAY_MS \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(DELAY_MS \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000.0\u001b[39m)  \u001b[38;5;66;03m# Convert milliseconds to seconds\u001b[39;00m\n\u001b[1;32m     69\u001b[0m avro_producer\u001b[38;5;241m.\u001b[39mproduce(topic\u001b[38;5;241m=\u001b[39mKAFKA_TOPIC, value\u001b[38;5;241m=\u001b[39mvalue, on_delivery\u001b[38;5;241m=\u001b[39mdelivery_report_func)\n\u001b[1;32m     70\u001b[0m avro_producer\u001b[38;5;241m.\u001b[39mpoll(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Serve delivery callback queue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "def get_delivery_report_func(verbose):\n",
    "    def delivery_report(err, msg):\n",
    "        if verbose:\n",
    "            if err is not None:\n",
    "                print(f'Message delivery failed: {err}')\n",
    "            else:\n",
    "                print(f'Message delivered to {msg.topic()} [{msg.partition()}]')\n",
    "    return delivery_report\n",
    "\n",
    "def main():   \n",
    "    KAFKA_BROKER='broker:29092'\n",
    "    KAFKA_TOPIC='trades'\n",
    "    CSV_FILE='./tradesMarch.csv'\n",
    "    SCHEMA_REGISTRY='http://schema_registry:8081'\n",
    "    TIMESTAMP_FROM_FILE=False\n",
    "    VERBOSE=True\n",
    "    DELAY_MS=50\n",
    "\n",
    "    value_schema = avro.loads(\"\"\"\n",
    "    {\n",
    "        \"type\": \"record\",\n",
    "        \"name\": \"Trade\",\n",
    "        \"fields\": [\n",
    "            {\"name\": \"symbol\", \"type\": \"string\"},\n",
    "            {\"name\": \"side\", \"type\": \"string\"},\n",
    "            {\"name\": \"price\", \"type\": \"double\"},\n",
    "            {\"name\": \"amount\", \"type\": \"double\"},\n",
    "            {\"name\": \"timestamp\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\"}\n",
    "        ]\n",
    "    }\n",
    "    \"\"\")\n",
    "\n",
    "    avro_producer = AvroProducer({\n",
    "        'bootstrap.servers': KAFKA_BROKER,\n",
    "        'schema.registry.url': SCHEMA_REGISTRY,\n",
    "        'linger.ms': '100',  # Adjust based on your needs\n",
    "        'batch.size': '65536',  # Adjust based on your needs\n",
    "    }, default_value_schema=value_schema)\n",
    "\n",
    "    delivery_report_func = get_delivery_report_func(VERBOSE)\n",
    "\n",
    "    with open(CSV_FILE, mode='r') as file:\n",
    "        csv_reader = csv.DictReader(file)\n",
    "        for row in csv_reader:\n",
    "            if TIMESTAMP_FROM_FILE:\n",
    "                timestamp_dt = datetime.strptime(row['timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                timestamp_micros = int(timestamp_dt.timestamp() * 1e6)\n",
    "            else:\n",
    "                timestamp_micros = int(time.time() * 1e6)\n",
    "\n",
    "            value = {\n",
    "                \"symbol\": row['symbol'],\n",
    "                \"side\": row['side'],\n",
    "                \"price\": float(row['price']),\n",
    "                \"amount\": float(row['amount']),\n",
    "                \"timestamp\": timestamp_micros\n",
    "            }\n",
    "\n",
    "            if DELAY_MS > 0:\n",
    "                time.sleep(DELAY_MS / 1000.0)  # Convert milliseconds to seconds\n",
    "                \n",
    "            avro_producer.produce(topic=KAFKA_TOPIC, value=value, on_delivery=delivery_report_func)\n",
    "            avro_producer.poll(0)  # Serve delivery callback queue\n",
    "\n",
    "    avro_producer.flush()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d713e0c-97dd-417d-9d44-b4d28231b459",
   "metadata": {},
   "source": [
    "## Verify we have ingested some data\n",
    "\n",
    "The data you send to Kafka will be processed by Kafka Connect and passed to QuestDB, where it will be stored into a table named `trades`. Let's check we can actually see some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5dafaac-9a8e-4c55-a7cb-3cb1453f9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOT-USD', 'buy', 8.278547619047, 39.607455338095, '2024-02-29T23:00:00.080992Z']\n",
      "['LTC-USD', 'buy', 80.105555555555, 5.080278386, '2024-02-29T23:00:00.080992Z']\n",
      "['ETH-USD', 'buy', 3342.659019607845, 0.301281981078, '2024-02-29T23:00:00.080992Z']\n",
      "['BTC-USD', 'buy', 61196.341418918964, 0.0525110666891, '2024-02-29T23:00:00.080992Z']\n",
      "['XLM-USD', 'buy', 0.122351361445, 564.286784114338, '2024-02-29T23:00:00.080992Z']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "host = 'http://questdb:9000'\n",
    "\n",
    "sql_query = 'SELECT * FROM trades LIMIT 5;'\n",
    "\n",
    "try:\n",
    "    response = requests.get(\n",
    "        host + '/exec',\n",
    "        params={'query': sql_query}).json()\n",
    "    for row in response['dataset']:\n",
    "        print(row)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f'Error: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
