{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0868bc-01bb-4296-8206-bad1c9b9da83",
   "metadata": {},
   "source": [
    "# Send Trades To QuestDB directly\n",
    "\n",
    "This notebook will read the `./tradesMarch.csv` file to read trading events, and will send the events directly to QuestDB using multiple process in parallel.\n",
    "\n",
    "We first create the QuestDB table. It would automatically be created if it didn't exist in any case, but this way we can see the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9613c-bf7d-47be-8235-dab0de85e945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore deprecation warnings in this demo\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9835b8-2b20-4b1c-b893-5ef647db99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg as pg\n",
    "\n",
    "\n",
    "conn_str = 'user=admin password=quest host=questdb port=8812 dbname=qdb'\n",
    "with pg.connect(conn_str, autocommit=True) as connection:\n",
    "    with connection.cursor() as cur:\n",
    "        cur.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS  'trades' (\n",
    "  symbol SYMBOL capacity 256 CACHE,\n",
    "  side SYMBOL capacity 256 CACHE,\n",
    "  price DOUBLE,\n",
    "  amount DOUBLE,\n",
    "  timestamp TIMESTAMP\n",
    ") timestamp (timestamp) PARTITION BY DAY WAL DEDUP UPSERT KEYS(timestamp, symbol, side);\n",
    "\"\"\")\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e215-ffd0-4aef-b526-a65143e7e554",
   "metadata": {},
   "source": [
    "## Sending the data to QuestDB\n",
    "\n",
    "Now we read the `./tradesMarch.csv` file and we insert into the trades table.\n",
    "\n",
    "By default, the script will override the original date with the current date and\n",
    " will wait 50ms between events before sending to QuestDB, to simulate a real time stream and provide\n",
    "a nicer visualization. You can override those configurations by changing the constants in the script. \n",
    "\n",
    "This script will keep sending data until you click stop or exit the notebook, or until the `TOTAL_EVENTS` number is reached. If the number of events on the CSV is smaller than the total events configured, the script will sumply loop over the file again.\n",
    "\n",
    "While the script is running, you can check the data in the table directly at QuestDB's web console at http://localhost:9000 or a live Grafana Dashboard powered by QuestDB at http://localhost:3000/d/trades-crypto-currency/trades-crypto-currency?orgId=1&refresh=250ms (user admin and password quest).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea7e3177-5269-433a-82af-5618181e90d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingestion started. Connecting to host.docker.internal:9000\n",
      "Sender 0 will send 142858 events\n",
      "Sender 3 will send 142857 events\n",
      "Sender 4 will send 142857 events\n",
      "Sender 1 will send 142857 events\n",
      "Sender 2 will send 142857 events\n",
      "Sender 6 will send 142857 events\n",
      "Sender 5 will send 142857 events\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 72\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     71\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIngestion started. Connecting to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHTTP_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mparallel_send\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTOTAL_EVENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_SENDERS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 68\u001b[0m, in \u001b[0;36mparallel_send\u001b[0;34m(total_events, num_senders)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mnum_senders) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     67\u001b[0m     sender_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(num_senders)\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msender_events\u001b[49m\u001b[43m[\u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msender_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msender_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from questdb.ingress import Sender, IngressError, TimestampNanos\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from datetime import datetime\n",
    "\n",
    "HTTP_ENDPOINT = os.getenv('QUESTDB_HTTP_ENDPOINT', 'questdb:9000')\n",
    "\n",
    "TOTAL_EVENTS = 1000000  # Total events across all senders\n",
    "DELAY_MS = 50  # Delay between events in milliseconds\n",
    "NUM_SENDERS = 7  # Number of senders to execute in parallel\n",
    "CSV_FILE = './tradesMarch.csv'  # Path to the CSV file\n",
    "TIMESTAMP_FROM_FILE = False  # Whether to use the timestamp from the CSV file\n",
    "\n",
    "def send(sender_id, total_events, delay_ms=DELAY_MS, csv_file=CSV_FILE, http_endpoint=HTTP_ENDPOINT, auth=None):\n",
    "    sys.stdout.write(f\"Sender {sender_id} will send {total_events} events\\n\")\n",
    "\n",
    "    try:\n",
    "        conf = f'http::addr={http_endpoint};'\n",
    "        with Sender.from_conf(conf) as sender, open(csv_file, mode='r') as file:\n",
    "            csv_reader = csv.DictReader(file)\n",
    "            events_sent = 0\n",
    "            csv_rows = list(csv_reader)  # Load the CSV data once into memory for looping\n",
    "\n",
    "            while events_sent < total_events:\n",
    "                row = csv_rows[events_sent % len(csv_rows)]  # Loop over the CSV rows\n",
    "\n",
    "                if TIMESTAMP_FROM_FILE:\n",
    "                    timestamp_dt = datetime.strptime(row['timestamp'], \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "                    timestamp_nanos = int(timestamp_dt.timestamp() * 1e9)  # Convert to nanoseconds\n",
    "                else:\n",
    "                    timestamp_nanos = TimestampNanos.now()  # Get current time in nanoseconds\n",
    "                \n",
    "                # Ingest the row with the current timestamp\n",
    "                sender.row(\n",
    "                    'trades',\n",
    "                    symbols={'symbol': row['symbol'], 'side': row['side']},\n",
    "                    columns={\n",
    "                        'price': float(row['price']),\n",
    "                        'amount': float(row['amount']),\n",
    "                    },\n",
    "                    at=timestamp_nanos  # Send timestamp in nanoseconds\n",
    "                )\n",
    "\n",
    "                events_sent += 1\n",
    "\n",
    "                # Delay after each event\n",
    "                if delay_ms > 0:\n",
    "                    time.sleep(delay_ms / 1000.0)  # Convert milliseconds to seconds\n",
    "\n",
    "            sys.stdout.write(f\"Sender {sender_id} finished sending {events_sent} events\\n\")\n",
    "\n",
    "    except IngressError as e:\n",
    "        sys.stderr.write(f'Sender {sender_id} got error: {e}\\n')\n",
    "\n",
    "def parallel_send(total_events, num_senders: int):\n",
    "    events_per_sender = total_events // num_senders\n",
    "    remaining_events = total_events % num_senders\n",
    "\n",
    "    sender_events = [events_per_sender] * num_senders\n",
    "    for i in range(remaining_events):  # Distribute the remaining events\n",
    "        sender_events[i] += 1\n",
    "\n",
    "    with Pool(processes=num_senders) as pool:\n",
    "        sender_ids = range(num_senders)\n",
    "        pool.starmap(send, [(sender_id, sender_events[sender_id]) for sender_id in sender_ids])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sys.stdout.write(f'Ingestion started. Connecting to {HTTP_ENDPOINT}\\n')\n",
    "    parallel_send(TOTAL_EVENTS, NUM_SENDERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d713e0c-97dd-417d-9d44-b4d28231b459",
   "metadata": {},
   "source": [
    "## Verify we have ingested some data\n",
    "\n",
    "The data you send to Kafka will be processed by Kafka Connect and passed to QuestDB, where it will be stored into a table named `trades`. Let's check we can actually see some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5dafaac-9a8e-4c55-a7cb-3cb1453f9e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ETH-BTC', 'sell', 0.054582, 0.4221111648, '2024-09-16T23:27:31.884616Z']\n",
      "['BTC-USDT', 'sell', 61178.369999999995, 0.0307306033333, '2024-09-16T23:27:31.885527Z']\n",
      "['BTC-USDT', 'sell', 61178.369999999995, 0.0307306033333, '2024-09-16T23:27:31.889579Z']\n",
      "['BTC-USDT', 'sell', 61178.369999999995, 0.0307306033333, '2024-09-16T23:27:31.913519Z']\n",
      "['BTC-USDT', 'sell', 61178.369999999995, 0.0307306033333, '2024-09-16T23:27:31.935605Z']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "host = 'http://questdb:9000'\n",
    "\n",
    "sql_query = 'SELECT * FROM trades LIMIT -5;'\n",
    "\n",
    "try:\n",
    "    response = requests.get(\n",
    "        host + '/exec',\n",
    "        params={'query': sql_query}).json()\n",
    "    for row in response['dataset']:\n",
    "        print(row)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f'Error: {e}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
