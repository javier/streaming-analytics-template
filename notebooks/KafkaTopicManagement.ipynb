{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12753a24-20eb-44e4-8401-383b4ed1d7e0",
   "metadata": {},
   "source": [
    "# Kafka Topic Management\n",
    "\n",
    "Topics in Kafka are typically auto created. In this notebook we can explore the topics that already exists on the server and, optionally, we can change the replication factor or number of partitions for a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a1e748-e3e7-43d7-8dd3-459f08bc6190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic List with Partition and Replication Details:\n",
      "\n",
      "Topic 'docker-connect-status': Partitions = 5, Replication Factor = 2\n",
      "Topic 'iot_data': Partitions = 1, Replication Factor = 1\n",
      "Topic 'docker-connect-configs': Partitions = 1, Replication Factor = 2\n",
      "Topic '_schemas': Partitions = 1, Replication Factor = 2\n",
      "Topic 'docker-connect-offsets': Partitions = 25, Replication Factor = 2\n",
      "Topic 'github_events': Partitions = 1, Replication Factor = 1\n",
      "Topic 'trades': Partitions = 1, Replication Factor = 2\n",
      "Topic '_confluent-monitoring': Partitions = 1, Replication Factor = 1\n",
      "Topic 'smart-meters': Partitions = 1, Replication Factor = 1\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient\n",
    "\n",
    "# Kafka broker addresses\n",
    "KAFKA_BROKER = 'broker:29092,broker-2:29092'\n",
    "\n",
    "# Initialize the AdminClient\n",
    "admin_client = AdminClient({'bootstrap.servers': KAFKA_BROKER})\n",
    "\n",
    "# Retrieve cluster metadata\n",
    "cluster_metadata = admin_client.list_topics(timeout=10)\n",
    "\n",
    "print(\"Topic List with Partition and Replication Details:\\n\")\n",
    "\n",
    "for topic_name, topic_metadata in cluster_metadata.topics.items():\n",
    "    # Skip internal topics (those that start with '__')\n",
    "    if topic_name.startswith('__'):\n",
    "        continue\n",
    "\n",
    "    partition_count = len(topic_metadata.partitions)\n",
    "    # Assume replication factor is the number of replicas of the first partition\n",
    "    # Check if there are partitions\n",
    "    if partition_count > 0:\n",
    "        first_partition = next(iter(topic_metadata.partitions.values()))\n",
    "        replication_factor = len(first_partition.replicas)\n",
    "    else:\n",
    "        replication_factor = 'Unknown'  # Topic with no partitions\n",
    "\n",
    "    print(f\"Topic '{topic_name}': Partitions = {partition_count}, Replication Factor = {replication_factor}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5d6176-69c3-48de-b74a-c72b2225b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 'trades' deleted.\n",
      "Topic 'trades' has been fully deleted.\n",
      "Topic 'trades' created with 1 partitions.\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "import time\n",
    "\n",
    "KAFKA_BROKER = 'broker:29092,broker-2:29092'\n",
    "KAFKA_TOPIC = 'trades'\n",
    "PARTITIONS = 1\n",
    "REPLICATION_FACTOR = 2  # Should not exceed the number of brokers in your cluster\n",
    "\n",
    "# Initialize the AdminClient\n",
    "admin_client = AdminClient({'bootstrap.servers': KAFKA_BROKER})\n",
    "\n",
    "# Check if the topic exists\n",
    "metadata = admin_client.list_topics(timeout=10)\n",
    "if KAFKA_TOPIC in metadata.topics:\n",
    "    # Delete the topic if it exists\n",
    "    delete_futures = admin_client.delete_topics([KAFKA_TOPIC])\n",
    "    for topic, future in delete_futures.items():\n",
    "        try:\n",
    "            future.result()  # Wait for the operation to finish\n",
    "            print(f\"Topic '{topic}' deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete topic '{topic}': {e}\")\n",
    "            # You may choose to exit or handle the error as needed\n",
    "\n",
    "    # Wait until the topic is fully deleted    \n",
    "    while True:\n",
    "        metadata = admin_client.list_topics(timeout=10)\n",
    "        if KAFKA_TOPIC not in metadata.topics:\n",
    "            print(f\"Topic '{KAFKA_TOPIC}' has been fully deleted.\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Waiting for topic '{KAFKA_TOPIC}' to be deleted...\")\n",
    "            time.sleep(1)\n",
    "\n",
    "# Create a new topic with the desired number of partitions\n",
    "new_topic = NewTopic(\n",
    "    topic=KAFKA_TOPIC,\n",
    "    num_partitions=PARTITIONS,\n",
    "    replication_factor=REPLICATION_FACTOR\n",
    ")\n",
    "\n",
    "create_futures = admin_client.create_topics([new_topic])\n",
    "for topic, future in create_futures.items():\n",
    "    try:\n",
    "        future.result()  # Wait for the operation to finish\n",
    "        print(f\"Topic '{topic}' created with {PARTITIONS} partitions.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create topic '{topic}': {e}\")\n",
    "        # You may choose to exit or handle the error as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
