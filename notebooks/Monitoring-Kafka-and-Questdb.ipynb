{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c37bdd4e-3143-4fea-ac60-a29005c74f9d",
   "metadata": {},
   "source": [
    "# Monitoring Kafka and Questdb\n",
    "\n",
    "To monitor data, you usually have an agent running on your servers that collects metrics and then ingest into a time-series database. There are many agents to choose from, but a popular option that works well with Kafka and QuestDB is the Telegraf Agent. Telegraf supports many input plugins as metrics origin, many output plugins as metrics destination, and supports aggregators and transforms between input and output.\n",
    "\n",
    "In this template, we have a telegraf configuration in the `./monitoring/telegraf` folder. That configuration reads metrics from the questdb monitoring endpoint (in prometheus format) `questdb:9003/metrics` and from the Kafka MX metrics server that we are exposing through a plugin on `http://broker:8778/jolokia`. After collecting the metrics and applying some filtering and transforms, metrics are then written into several tables in QuestDB.\n",
    "\n",
    "On a production environment you would probably want to store metrics on a different server, but for this template we are storing the metrics in the same QuestDB instance where we store the user data.\n",
    "\n",
    "We are not providing any monitoring dashboard on this template, but feel free to explore the metrics on this notebook, or even better at [http://localhost:9000](http://localhost:9000), and then try to create a Grafana dashboard at [http://localhost:3000](http://localhost:3000)\n",
    "\n",
    "You can see the monitoring tables with this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9835b8-2b20-4b1c-b893-5ef647db99e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealDictRow([('table_name', 'kafka_cluster')])\n",
      "RealDictRow([('table_name', 'trades')])\n",
      "RealDictRow([('table_name', 'kafka_java_runtime')])\n",
      "RealDictRow([('table_name', 'kafka_topic')])\n",
      "RealDictRow([('table_name', 'prometheus')])\n",
      "RealDictRow([('table_name', 'kafka_partition')])\n",
      "RealDictRow([('table_name', 'github_events')])\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg\n",
    "import time\n",
    "import json\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import os\n",
    "\n",
    "# Fetch environment variables with defaults\n",
    "host = os.getenv('QDB_CLIENT_HOST', 'questdb')\n",
    "port = os.getenv('QDB_CLIENT_PORT', '8812')\n",
    "user = os.getenv('QDB_CLIENT_USER', 'admin')\n",
    "password = os.getenv('QDB_CLIENT_PASSWORD', 'quest')\n",
    "\n",
    "# Create the connection string using the environment variables or defaults\n",
    "conn_str = f'user={user} password={password} host={host} port={port} dbname=qdb'\n",
    "\n",
    "connection = pg.connect(conn_str)\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cur = connection.cursor(cursor_factory=RealDictCursor)\n",
    "\n",
    "#Query the database and obtain data as Python objects.\n",
    "cur.execute('show tables;')\n",
    "records = cur.fetchall()\n",
    "for row in records:\n",
    "     print(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944fd764-9753-47a5-88be-5d9394b9c021",
   "metadata": {},
   "source": [
    "As you can see, apart from any analytics tables, we have the `kafka_cluster`, `kafka_java_runtime`, `kafka_partition`, and `kafka_topic` tables to monitor Kafka, and the `prometheus` table to monitor QuestDB.\n",
    "\n",
    "Let's explore these tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae3f492-ef52-47d7-9f30-ae5c6c3902e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealDictRow([('system', 'kafka_jvm'), ('Uptime', 4956010.0), ('G1 Old GenerationCollectionCount', 0.0), ('G1 Young GenerationCollectionTime', 2621.0), ('ThreadCount', 87.0), ('LoadedClassCount', 7582.0), ('TotalLoadedClassCount', 7582.0), ('G1 Old GenerationCollectionTime', 0.0), ('G1 Young GenerationCollectionCount', 114.0), ('TotalStartedThreadCount', 89.0), ('PeakThreadCount', 87.0), ('DaemonThreadCount', 43.0), ('UnloadedClassCount', 0.0), ('timestamp', datetime.datetime(2024, 2, 2, 19, 55, 30, 15000))])\n"
     ]
    }
   ],
   "source": [
    "#Query the database and obtain data as Python objects.\n",
    "cur.execute('select * from kafka_java_runtime limit -1;')\n",
    "records = cur.fetchall()\n",
    "for row in records:\n",
    "     print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d14d9-1820-4f47-a7cf-012e64589e0d",
   "metadata": {},
   "source": [
    "Garbage Collector statistics in 1 minute intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1acda30-1689-4f92-8b6a-12c860a9aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 0)), ('GC_1m', 2747.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 1)), ('GC_1m', 2830.5)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 2)), ('GC_1m', 2859.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 3)), ('GC_1m', 2902.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 4)), ('GC_1m', 2910.0)])\n"
     ]
    }
   ],
   "source": [
    "#Query the database and obtain data as Python objects.\n",
    "cur.execute('select timestamp, avg(`G1 Young GenerationCollectionTime`) as GC_1m from kafka_java_runtime sample by 1m align to calendar limit -5')\n",
    "records = cur.fetchall()\n",
    "for row in records:\n",
    "     print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda15ce6-8811-42e3-b0f7-2549983b86e2",
   "metadata": {},
   "source": [
    "Some topic statistics per minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37ccb659-750c-47af-a28b-ef1c4c0d0339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 19, 52)), ('bytesOut', 1642013.0), ('requests', 19630.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 19, 54)), ('bytesOut', 1693265.0), ('requests', 20189.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 19, 57)), ('bytesOut', 1772884.0), ('requests', 21040.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 1)), ('bytesOut', 1866938.0), ('requests', 22040.0)])\n",
      "RealDictRow([('timestamp', datetime.datetime(2024, 2, 2, 20, 3)), ('bytesOut', 1923234.0), ('requests', 22627.0)])\n"
     ]
    }
   ],
   "source": [
    "#Query the database and obtain data as Python objects.\n",
    "cur.execute(\"select timestamp, AVG(BytesOutPerSec_github_events_Count) as bytesOut, AVG(TotalFetchRequestsPerSec_github_events_Count) AS requests from kafka_topic where topic = 'github_events' SAMPLE BY 1m align to calendar limit -5;\")\n",
    "records = cur.fetchall()\n",
    "for row in records:\n",
    "     print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba20206d-7ee0-471d-bfec-3471b28c5380",
   "metadata": {},
   "source": [
    "Some QuestDB metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ba08556-f19d-4623-b482-69913b1cc3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RealDictRow([('malloc', 201772.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 214739.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 227711.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 240713.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 253800.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 266965.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 280190.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 293385.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 306646.0), ('GC', 14.0)])\n",
      "RealDictRow([('malloc', 158324.0), ('GC', 7.0)])\n"
     ]
    }
   ],
   "source": [
    "#Query the database and obtain data as Python objects.\n",
    "cur.execute(\"select SUM(questdb_memory_malloc_count) as malloc, SUM(questdb_jvm_minor_gc_count_total) as GC from prometheus  SAMPLE by 1m ALIGN TO CALENDAR limit -10;\")\n",
    "records = cur.fetchall()\n",
    "for row in records:\n",
    "     print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0f8545-ef75-4559-a591-aa6536394514",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
